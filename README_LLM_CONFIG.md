# LLM API ç»Ÿä¸€é…ç½®æ–¹æ¡ˆ

## ğŸ¯ æ–¹æ¡ˆæ¦‚è¿°

æœ¬é¡¹ç›®é‡‡ç”¨**åŸºäºåœºæ™¯çš„ LLM æ¨¡å‹é…ç½®**æ–¹æ¡ˆï¼Œå®Œç¾é€‚é…ä½ ä½¿ç”¨ OpenAI ä¸­è½¬ key çš„éœ€æ±‚ã€‚

### æ ¸å¿ƒç‰¹æ€§

âœ… **ç»Ÿä¸€ API é…ç½®** - æ‰€æœ‰æ¨¡å‹å…±ç”¨ä¸€ä¸ª API Key å’Œ Base URL  
âœ… **åœºæ™¯åŒ–æ¨¡å‹** - ä¸åŒå·¥å…·å¯ä½¿ç”¨ä¸åŒæ¨¡å‹ï¼ˆä»£ç ç”Ÿæˆã€è§†è§‰ç†è§£ç­‰ï¼‰  
âœ… **çµæ´»åˆ‡æ¢** - åªéœ€ä¿®æ”¹ `.env` æ–‡ä»¶ä¸­çš„æ¨¡å‹åå³å¯åˆ‡æ¢  
âœ… **ç®€å•æ˜“ç”¨** - ä¸€è¡Œä»£ç åˆ›å»ºå¯¹åº”åœºæ™¯çš„ LLM å®¢æˆ·ç«¯  

## ğŸ“ æ–‡ä»¶ç»“æ„

```
HtmlParserAgent/
â”œâ”€â”€ .env                          # ä½ çš„é…ç½®æ–‡ä»¶ï¼ˆå·²æ›´æ–°ï¼‰
â”œâ”€â”€ .env.example                  # é…ç½®æ¨¡æ¿ï¼ˆæ–°å¢ï¼‰
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py              # Settings ç±»ï¼ˆå·²ä¼˜åŒ–ï¼‰
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ llm_client.py            # LLMClient ç±»ï¼ˆå·²å¢å¼ºï¼‰
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ code_generator.py        # ä»£ç ç”Ÿæˆå·¥å…·ï¼ˆå·²æ›´æ–°ï¼‰
â”‚   â””â”€â”€ visual_understanding.py  # è§†è§‰ç†è§£å·¥å…·ï¼ˆå·²æ›´æ–°ï¼‰
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ check_config.py          # é…ç½®æ£€æŸ¥å·¥å…·ï¼ˆæ–°å¢ï¼‰
â”‚   â””â”€â”€ test_llm_config.py       # å®Œæ•´æµ‹è¯•è„šæœ¬ï¼ˆæ–°å¢ï¼‰
â””â”€â”€ docs/
    â”œâ”€â”€ LLM_CONFIG_GUIDE.md      # è¯¦ç»†é…ç½®æŒ‡å—ï¼ˆæ–°å¢ï¼‰
    â””â”€â”€ CONFIG_MIGRATION.md      # è¿ç§»è¯´æ˜ï¼ˆæ–°å¢ï¼‰
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æŸ¥çœ‹å½“å‰é…ç½®

```bash
python examples/check_config.py
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
âœ… æ‰€æœ‰é…ç½®æ­£å¸¸

ğŸ“Œ é»˜è®¤åœºæ™¯ (default)
   model: claude-sonnet-4-5-20250929
   temperature: 0

ğŸ“Œ ä»£ç ç”Ÿæˆ (code_gen)
   model: claude-sonnet-4-5-20250929
   temperature: 0.3

ğŸ“Œ è§†è§‰ç†è§£ (vision)
   model: qwen-vl-max
   temperature: 0
```

### 2. åœ¨ä»£ç ä¸­ä½¿ç”¨

```python
from utils.llm_client import LLMClient

# ä»£ç ç”Ÿæˆåœºæ™¯
llm = LLMClient.for_scenario("code_gen")
response = llm.chat_completion(messages=[...])

# è§†è§‰ç†è§£åœºæ™¯
llm = LLMClient.for_scenario("vision")
response = llm.vision_completion(prompt="...", image_data="...")

# Agent åœºæ™¯
llm = LLMClient.for_scenario("agent")
```

### 3. åˆ‡æ¢æ¨¡å‹

åªéœ€ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```bash
# åˆ‡æ¢ä»£ç ç”Ÿæˆæ¨¡å‹ä¸º GPT-4
CODE_GEN_MODEL=gpt-4-turbo-preview

# åˆ‡æ¢è§†è§‰æ¨¡å‹ä¸º GPT-4V
VISION_MODEL=gpt-4-vision-preview
```

## ğŸ“‹ é…ç½®è¯´æ˜

### .env æ–‡ä»¶ç»“æ„

```bash
# ============================================
# ç»Ÿä¸€ API é…ç½®ï¼ˆæ‰€æœ‰åœºæ™¯å…±ç”¨ï¼‰
# ============================================
OPENAI_API_KEY=sk-xxx                    # ä½ çš„ä¸­è½¬ key
OPENAI_API_BASE=http://xxx/v1            # ä¸­è½¬æœåŠ¡åœ°å€

# ============================================
# åœºæ™¯åŒ–æ¨¡å‹é…ç½®
# ============================================
DEFAULT_MODEL=claude-sonnet-4-5-20250929      # é»˜è®¤æ¨¡å‹
CODE_GEN_MODEL=claude-sonnet-4-5-20250929     # ä»£ç ç”Ÿæˆ
VISION_MODEL=qwen-vl-max                       # è§†è§‰ç†è§£
AGENT_MODEL=claude-sonnet-4-5-20250929        # Agent

# åœºæ™¯å‚æ•°
CODE_GEN_TEMPERATURE=0.3
CODE_GEN_MAX_TOKENS=8192
VISION_TEMPERATURE=0
VISION_MAX_TOKENS=4096
```

### æ”¯æŒçš„åœºæ™¯

| åœºæ™¯ | ä»£ç  | ç”¨é€” | å½“å‰æ¨¡å‹ |
|------|------|------|---------|
| é»˜è®¤ | `for_scenario("default")` | é€šç”¨åœºæ™¯ | claude-sonnet-4-5 |
| ä»£ç ç”Ÿæˆ | `for_scenario("code_gen")` | ç”Ÿæˆè§£æä»£ç  | claude-sonnet-4-5 |
| è§†è§‰ç†è§£ | `for_scenario("vision")` | å›¾ç‰‡åˆ†æ | qwen-vl-max |
| Agent | `for_scenario("agent")` | LangChain Agent | claude-sonnet-4-5 |

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šå·¥å…·ä¸­ä½¿ç”¨

```python
# tools/code_generator.py
from utils.llm_client import LLMClient

@tool
def generate_code_from_html(html_content: str, target_json: Dict, ...):
    # è‡ªåŠ¨ä½¿ç”¨ CODE_GEN_MODEL é…ç½®
    llm = LLMClient.for_scenario("code_gen")
    response = llm.chat_completion(messages=[...])
    return response
```

### ç¤ºä¾‹ 2ï¼šè‡ªå®šä¹‰æ¨¡å‹

```python
# ä¸´æ—¶ä½¿ç”¨ç‰¹å®šæ¨¡å‹
llm = LLMClient(model="gpt-4-turbo-preview", temperature=0.7)
response = llm.chat_completion(messages=[...])
```

### ç¤ºä¾‹ 3ï¼šæ··åˆä½¿ç”¨

```python
# ä»£ç ç”Ÿæˆç”¨ Claude
code_llm = LLMClient.for_scenario("code_gen")  # claude-sonnet-4-5

# è§†è§‰ç†è§£ç”¨ Qwen
vision_llm = LLMClient.for_scenario("vision")  # qwen-vl-max

# éƒ½ä½¿ç”¨åŒä¸€ä¸ª API Key å’Œ Base URL
```

## ğŸ”§ å·¥å…·å’Œæ–‡æ¡£

### é…ç½®å·¥å…·

- `examples/check_config.py` - å¿«é€Ÿæ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®
- `examples/test_llm_config.py` - å®Œæ•´åŠŸèƒ½æµ‹è¯•ï¼ˆéœ€è¦å®‰è£…ä¾èµ–ï¼‰

### æ–‡æ¡£

- `docs/LLM_CONFIG_GUIDE.md` - è¯¦ç»†é…ç½®æŒ‡å—
- `docs/CONFIG_MIGRATION.md` - è¿ç§»è¯´æ˜
- `.env.example` - é…ç½®æ¨¡æ¿

## âœ¨ ä¼˜åŠ¿

### 1. å®Œç¾é€‚é…ä¸­è½¬æœåŠ¡

```bash
# åªéœ€é…ç½®ä¸€æ¬¡ API Key å’Œ Base URL
OPENAI_API_KEY=sk-xxx
OPENAI_API_BASE=http://your-proxy.com/v1

# æ‰€æœ‰åœºæ™¯è‡ªåŠ¨ä½¿ç”¨è¿™ä¸ªé…ç½®
```

### 2. çµæ´»çš„æ¨¡å‹é€‰æ‹©

```bash
# ä¸åŒåœºæ™¯ç”¨ä¸åŒæ¨¡å‹
CODE_GEN_MODEL=claude-sonnet-4-5-20250929  # ä»£ç ç”Ÿæˆç”¨ Claude
VISION_MODEL=qwen-vl-max                    # è§†è§‰ç†è§£ç”¨ Qwen
AGENT_MODEL=gpt-4-turbo-preview             # Agent ç”¨ GPT-4
```

### 3. ç®€æ´çš„ä»£ç 

```python
# ä¹‹å‰ï¼šéœ€è¦æ‰‹åŠ¨é…ç½®
llm = LLMClient(
    api_key=os.getenv("OPENAI_API_KEY"),
    api_base=os.getenv("OPENAI_API_BASE"),
    model=os.getenv("VISION_MODEL"),
    temperature=0
)

# ç°åœ¨ï¼šä¸€è¡Œæå®š
llm = LLMClient.for_scenario("vision")
```

## ğŸ“ å¸¸è§é—®é¢˜

**Q: å¦‚ä½•åˆ‡æ¢æ¨¡å‹ï¼Ÿ**  
A: ç¼–è¾‘ `.env` æ–‡ä»¶ä¸­å¯¹åº”åœºæ™¯çš„ `*_MODEL` é…ç½®å³å¯ã€‚

**Q: æ‰€æœ‰åœºæ™¯å¿…é¡»é…ç½®å—ï¼Ÿ**  
A: ä¸å¿…é¡»ã€‚æœªé…ç½®çš„åœºæ™¯ä¼šä½¿ç”¨ `DEFAULT_MODEL`ã€‚

**Q: å¯ä»¥ä¸ºå•ä¸ªè°ƒç”¨æŒ‡å®šæ¨¡å‹å—ï¼Ÿ**  
A: å¯ä»¥ã€‚ä½¿ç”¨ `LLMClient(model="xxx")` ç›´æ¥åˆå§‹åŒ–ã€‚

**Q: æ—§ä»£ç ä¼šå—å½±å“å—ï¼Ÿ**  
A: ä¸ä¼šã€‚Settings ç±»æä¾›äº†å‘åå…¼å®¹ã€‚

## ğŸ‰ æ€»ç»“

è¿™ä¸ªé…ç½®æ–¹æ¡ˆï¼š

1. âœ… **ç»Ÿä¸€ç®¡ç†** - ä¸€ä¸ª API Keyï¼Œä¸€ä¸ª Base URL
2. âœ… **çµæ´»é…ç½®** - ä¸åŒåœºæ™¯ç”¨ä¸åŒæ¨¡å‹
3. âœ… **ç®€å•åˆ‡æ¢** - åªéœ€ä¿®æ”¹ `.env` æ–‡ä»¶
4. âœ… **ä»£ç ç®€æ´** - ä¸€è¡Œä»£ç åˆ›å»ºå®¢æˆ·ç«¯
5. âœ… **å®Œç¾é€‚é…** - ä¸“ä¸º OpenAI ä¸­è½¬æœåŠ¡è®¾è®¡

ç°åœ¨ä½ å¯ä»¥ï¼š
- è¿è¡Œ `python examples/check_config.py` æŸ¥çœ‹é…ç½®
- åœ¨ä»£ç ä¸­ä½¿ç”¨ `LLMClient.for_scenario("xxx")` åˆ›å»ºå®¢æˆ·ç«¯
- éšæ—¶ä¿®æ”¹ `.env` åˆ‡æ¢æ¨¡å‹

æœ‰ä»»ä½•é—®é¢˜ï¼ŒæŸ¥çœ‹ `docs/LLM_CONFIG_GUIDE.md` è·å–è¯¦ç»†è¯´æ˜ï¼

