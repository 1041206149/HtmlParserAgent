# ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

## å®‰è£…ä¾èµ–

```bash
# ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–
pip install -r requirements.txt

# æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
pip list | grep -E "langchain|openai|beautifulsoup"
```

## é…ç½®ç¯å¢ƒå˜é‡

```bash
# åˆ›å»º .env æ–‡ä»¶æˆ–è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="sk-your-key-here"
export OPENAI_API_BASE="https://api.openai.com/v1"  # æˆ–ä½¿ç”¨è‡ªå®šä¹‰åŸºåœ°å€
```

## å‡†å¤‡URLåˆ—è¡¨

åˆ›å»º `urls.txt` æ–‡ä»¶ï¼š

```
https://example.com/article1
https://example.com/article2
https://example.com/article3
https://example.com/article4
https://example.com/article5
```

## è¿è¡Œè¿­ä»£æµç¨‹

### æ–¹å¼1ï¼šå‘½ä»¤è¡Œï¼ˆæ¨èï¼‰

```bash
# åŸºç¡€è¿è¡Œ
python main.py -f urls.txt

# å®Œæ•´å‚æ•°
python main.py \
  -f urls.txt \
  -o output/my_project \
  -t article \
  -d example.com

# ç›‘æ§æ—¥å¿—
tail -f logs/agent_*.log
```

### æ–¹å¼2ï¼šPythonè„šæœ¬

```python
from agent import ParserAgent

agent = ParserAgent(output_dir="output/test")

result = agent.run_iterations(
    urls=[
        "https://example.com/page1",
        "https://example.com/page2",
        "https://example.com/page3",
    ],
    domain="example.com",
    layout_type="article",
    max_iterations=3,
    accuracy_threshold=0.85
)

print(f"âœ“ æ€»è½®æ¬¡: {result['total_rounds']}")
print(f"âœ“ æœ€ç»ˆå‡†ç¡®ç‡: {result['overall_accuracy']:.2%}")
print(f"âœ“ Parserè·¯å¾„: {result['final_parser_path']}")
```

## æŸ¥çœ‹ç»“æœ

### è¾“å‡ºæ–‡ä»¶

```bash
# æŸ¥çœ‹ç”Ÿæˆçš„Parser
cat output/parsers/generated_parser_v1.py

# æŸ¥çœ‹Schemaæ¼”å˜
cat output/parsers/schema_v1.json
cat output/parsers/schema_v2.json
cat output/parsers/schema_v3.json

# æŸ¥çœ‹æˆªå›¾
open output/screenshots/round_1_sample_1.png

# æŸ¥çœ‹groundtruth
cat output/groundtruth/12345678.json
```

### æ€§èƒ½æŒ‡æ ‡

```bash
# æŸ¥çœ‹æ—¥å¿—ä¸­çš„å‡†ç¡®ç‡
grep "æ€»ä½“å‡†ç¡®ç‡\|æ•´ä½“å‡†ç¡®ç‡" logs/agent_*.log

# æŸ¥çœ‹è¿­ä»£æ¬¡æ•°
grep "è¿­ä»£è½®æ¬¡" logs/agent_*.log
```

## ä½¿ç”¨ç”Ÿæˆçš„Parser

ç”Ÿæˆçš„Parserå¯ä»¥ç‹¬ç«‹ä½¿ç”¨ï¼š

```python
import sys
sys.path.insert(0, 'output/parsers')

from generated_parser_v3 import WebPageParser

parser = WebPageParser()

# ä»URLè§£æ
import requests
from urllib.parse import urlparse

url = "https://example.com/article"
response = requests.get(url)
result = parser.parse(response.text)

print(result)
# è¾“å‡º:
# {
#     "title": "...",
#     "date": "...",
#     "content": "...",
#     ...
# }
```

## å¸¸è§å‚æ•°è°ƒæ•´

### æé«˜å‡†ç¡®ç‡

```python
# å¢åŠ è¿­ä»£æ¬¡æ•°
result = agent.run_iterations(
    urls=urls,
    max_iterations=5  # ä»3å¢åŠ åˆ°5
)
```

### åŠ å¿«é€Ÿåº¦

```python
# é™ä½å‡†ç¡®ç‡é˜ˆå€¼
result = agent.run_iterations(
    urls=urls,
    accuracy_threshold=0.75  # ä»0.85é™ä½åˆ°0.75
)
```

### åªå¤„ç†éƒ¨åˆ†URL

```python
# é€‰æ‹©å‰Nä¸ªURL
result = agent.run_iterations(
    urls=urls[:5],  # åªå¤„ç†å‰5ä¸ª
)
```

## æ•…éšœæ’é™¤

### é—®é¢˜ï¼šAPIè¿æ¥å¤±è´¥

```
é”™è¯¯: Failed to connect to OpenAI API

è§£å†³:
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. æ£€æŸ¥ OPENAI_API_KEY æ˜¯å¦æ­£ç¡®
3. æ£€æŸ¥ OPENAI_API_BASE æ˜¯å¦æ­£ç¡®
4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯: tail logs/agent_*.log
```

### é—®é¢˜ï¼šå†…å­˜ä¸è¶³

```
é”™è¯¯: MemoryError

è§£å†³:
1. å‡å°‘URLæ•°é‡
2. é™ä½ max_iterations
3. æ£€æŸ¥æ˜¯å¦æœ‰åƒµå°¸è¿›ç¨‹: ps aux | grep python
```

### é—®é¢˜ï¼šæˆªå›¾å¤±è´¥

```
é”™è¯¯: Screenshot failed

è§£å†³:
1. æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆ
2. æ£€æŸ¥ç½‘ç»œè¿æ¥
3. å°è¯•æ‰‹åŠ¨è®¿é—®URL
4. æŸ¥çœ‹ output/screenshots/ ä¸­æ˜¯å¦æœ‰éƒ¨åˆ†æˆªå›¾
```

## ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯» [ITERATION_WORKFLOW.md](./ITERATION_WORKFLOW.md) äº†è§£è¯¦ç»†çš„å·¥ä½œæµç¨‹
- ğŸ“– é˜…è¯» [NEW_FLOW_GUIDE.md](./NEW_FLOW_GUIDE.md) äº†è§£æ–°æµç¨‹çš„æ”¹è¿›
- ğŸ”§ ç¼–è¾‘ `config/settings.py` è°ƒæ•´é…ç½®
- ğŸ§ª è¿è¡Œ `python test_new_flow.py` è¿›è¡Œæµ‹è¯•

## è·å–å¸®åŠ©

1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼š`logs/agent_*.log`
2. æ£€æŸ¥è¾“å‡ºæ–‡ä»¶ï¼š`output/` ç›®å½•
3. æŸ¥çœ‹ä»£ç æ³¨é‡Šï¼š`agent/` å’Œ `tools/` ç›®å½•

---

**æç¤º**ï¼šç¬¬ä¸€æ¬¡è¿è¡Œå¯èƒ½ä¼šè¾ƒæ…¢ï¼Œå› ä¸ºéœ€è¦åˆå§‹åŒ–å„ç§å·¥å…·å’ŒLLMè°ƒç”¨ã€‚åç»­è½®æ¬¡ä¼šå› ä¸ºåŸºäºå‰ä¸€è½®ä¼˜åŒ–è€Œæ›´å¿«ã€‚

