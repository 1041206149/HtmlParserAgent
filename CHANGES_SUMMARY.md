# ğŸ“ ä¿®æ”¹æ€»ç»“

## æ¦‚è¿°

æˆåŠŸé‡æ–°ç¼–å†™äº† HtmlParserAgent çš„æ ¸å¿ƒæµç¨‹ï¼Œå®ç°äº†ç¬¦åˆæ‚¨éœ€æ±‚çš„**å¤šè½®è¿­ä»£å¾ªç¯ç³»ç»Ÿ**ã€‚

---

## âœ… å®Œæˆçš„éœ€æ±‚

### 1. å¾ªç¯æµç¨‹é‡æ„
æ‚¨éœ€è¦çš„å¾ªç¯æµç¨‹å·²å®ç°ï¼š

1. **è·å–HTMLæºç ** âœ…
   - ä½¿ç”¨ `get_webpage_source` å·¥å…·
   - æ”¯æŒå¤šä¸ªURL

2. **æˆªå›¾** âœ…
   - ä½¿ç”¨ `capture_webpage_screenshot` å·¥å…·
   - æŒ‰è½®æ¬¡å’Œæ ·æœ¬ç¼–å·ä¿å­˜

3. **æå–JSON Schema** âœ…
   - **ç¬¬ä¸€è½®**ï¼šä»é›¶æå–
   - **ç¬¬äºŒè½®+**ï¼šä¸å‰ä¸€è½®Schemaåˆå¹¶
   - ä½¿ç”¨ `extract_json_from_image` å·¥å…·

4. **ç”Ÿæˆ/ä¼˜åŒ–è§£æä»£ç ** âœ…
   - **ç¬¬ä¸€è½®**ï¼šä»é›¶ç”Ÿæˆ
   - **ç¬¬äºŒè½®+**ï¼šåŸºäºå‰ä¸€è½®è¿›è¡Œä¼˜åŒ–å’Œå¢é‡æ›´æ–°
   - ä½¿ç”¨ `generate_parser_code` å’Œ `fix_parser_code` å·¥å…·

### 2. éªŒè¯é€»è¾‘ä¿®æ”¹
å·²æŒ‰è¦æ±‚ä¿®æ”¹éªŒè¯é€»è¾‘ï¼š

âœ… **Groundtruthä¿å­˜**
- æ¯ä¸ªURLçš„æˆªå›¾è¯†åˆ«JSONä¿å­˜ä¸ºgroundtruth
- ä¿å­˜ä½ç½®ï¼š`output/groundtruth/{url_hash}.json`

âœ… **å‡†ç¡®ç‡è®¡ç®—**
- é¢„æµ‹å€¼ï¼šæœ€æ–°ä»£ç ç”Ÿæˆçš„JSON
- å‡†ç¡®ç‡å…¬å¼ï¼š`0.7 Ã— å­—æ®µå®Œæ•´æ€§ + 0.3 Ã— å­—æ®µå€¼ç›¸ä¼¼åº¦`
- æ¯è½®éƒ½è®¡ç®—æ‰€æœ‰URLçš„å‡†ç¡®ç‡

---

## ğŸ“ ä¿®æ”¹çš„æ–‡ä»¶

### 1. `agent/executor.py` âœ… å®Œå…¨é‡å†™
**èŒè´£**ï¼šæ‰§è¡Œå•è½®è¿­ä»£çš„å…·ä½“æ­¥éª¤

**æ–°å¢æ–¹æ³•**ï¼š
```python
execute_single_round(round_num, urls, domain, layout_type)
  â”œâ”€ è·å–HTML
  â”œâ”€ æˆªå›¾
  â”œâ”€ æå–JSON
  â””â”€ ä¿å­˜groundtruth

generate_or_update_parser(round_num, urls_data, previous_schema, previous_parser_path)
  â”œâ”€ ç¬¬ä¸€è½®ï¼šä»é›¶ç”Ÿæˆ
  â””â”€ åç»­è½®æ¬¡ï¼šåŸºäºå‰ä¸€è½®ä¼˜åŒ–

validate_parser_on_all_urls(parser_path, all_urls, groundtruth_dir, round_num)
  â”œâ”€ åŠ¨æ€åŠ è½½Parser
  â”œâ”€ åœ¨æ‰€æœ‰URLä¸Šè¿è¡Œ
  â”œâ”€ è®¡ç®—å‡†ç¡®ç‡
  â””â”€ è¿”å›è¯¦ç»†ç»“æœ

_merge_schemas_from_urls(urls_data, previous_schema, round_num)
  â”œâ”€ ç¬¬ä¸€è½®ï¼šæå–Schema
  â””â”€ åç»­è½®æ¬¡ï¼šåˆå¹¶Schema

_calculate_json_accuracy(groundtruth, predicted)
  â””â”€ è®¡ç®—groundtruthä¸predictedçš„å‡†ç¡®ç‡
```

### 2. `agent/orchestrator.py` âœ… å®Œå…¨é‡å†™
**èŒè´£**ï¼šç¼–æ’å¤šè½®è¿­ä»£æµç¨‹

**æ ¸å¿ƒæ–¹æ³•**ï¼š
```python
run_iterations(urls, domain, layout_type, max_iterations, accuracy_threshold)
  â””â”€ å¤šè½®å¾ªç¯
      â”œâ”€ Round 1: å¤„ç†å‰3ä¸ªURL
      â”œâ”€ Round 2+: å¤„ç†æ–°URL
      â”œâ”€ æ¯è½®æ‰§è¡Œï¼šè·å–HTML â†’ æˆªå›¾ â†’ æå–JSON
      â”œâ”€ æ¯è½®æ‰§è¡Œï¼šç”Ÿæˆ/ä¼˜åŒ–Parser
      â”œâ”€ æ¯è½®æ‰§è¡Œï¼šéªŒè¯æ‰€æœ‰URL
      â”œâ”€ æ£€æŸ¥æ˜¯å¦è¾¾åˆ°å‡†ç¡®ç‡é˜ˆå€¼
      â””â”€ æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
```

**å…³é”®æ”¹è¿›**ï¼š
- æ”¯æŒresumeåŠŸèƒ½
- æ”¯æŒåŠ¨æ€è°ƒæ•´max_iterationså’Œaccuracy_threshold
- å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—

### 3. `tools/code_fixer.py` âœ… å®Œå…¨é‡å†™
**èŒè´£**ï¼šåŸºäºå‰ä¸€è½®ä»£ç è¿›è¡Œä¼˜åŒ–

**æ–°ç­¾å**ï¼š
```python
fix_parser_code(
    previous_code: str,           # å‰ä¸€è½®çš„ä»£ç 
    html_content: str,            # å½“å‰è½®çš„HTML
    target_json: Dict,            # åˆå¹¶åçš„Schema
    output_dir: str,
    round_num: int
) -> Dict
```

**å·¥ä½œæ–¹å¼**ï¼š
- è¾“å…¥ï¼šå‰ä¸€è½®Parserä»£ç  + æ–°HTML + åˆå¹¶åçš„Schema
- è¿‡ç¨‹ï¼šLLMå¢é‡ä¼˜åŒ–ï¼ˆä¿ç•™å·²æœ‰é€»è¾‘ï¼Œæ·»åŠ æ–°å­—æ®µï¼Œæ”¹è¿›å®¹é”™ï¼‰
- è¾“å‡ºï¼šä¼˜åŒ–åçš„Parserä»£ç 

### 4. `main.py` âœ… æ›´æ–°
**æ”¹åŠ¨**ï¼š
- å°† `agent.generate_parser()` æ›¿æ¢ä¸º `agent.run_iterations()`
- æ›´æ–°ç»“æœå¤„ç†é€»è¾‘
- æ”¯æŒæ–°çš„å‚æ•°ä¼ é€’

---

## ğŸ—ï¸ æ¶æ„æ”¹è¿›

### æ—§æ¶æ„ âŒ

```
Planner â†’ Executor â†’ Validator
  â†“
  Execute once
  â”œâ”€ Get HTML
  â”œâ”€ Screenshot
  â”œâ”€ Extract JSON
  â””â”€ Generate Parser
  â†“
  Validate
  â†“
  Done
```

### æ–°æ¶æ„ âœ…

```
Orchestrator (å¤šè½®è¿­ä»£)
  â”œâ”€ Round 1
  â”‚   â”œâ”€ Executor.execute_single_round()
  â”‚   â”‚   â”œâ”€ Get HTML
  â”‚   â”‚   â”œâ”€ Screenshot
  â”‚   â”‚   â”œâ”€ Extract JSON
  â”‚   â”‚   â””â”€ Save groundtruth
  â”‚   â”œâ”€ Generate Schema v1
  â”‚   â”œâ”€ Generate Parser v1
  â”‚   â””â”€ Validate all URLs â†’ accuracy
  â”‚
  â”œâ”€ Round 2+
  â”‚   â”œâ”€ Executor.execute_single_round()
  â”‚   â”œâ”€ Merge Schema
  â”‚   â”œâ”€ Optimize Parser (based on v1)
  â”‚   â””â”€ Validate all URLs â†’ accuracy
  â”‚
  â””â”€ Loop until: accuracy â‰¥ threshold OR iterations â‰¥ max
```

---

## ğŸ“Š å·¥ä½œæµç¨‹å¯¹æ¯”

### æ—§æµç¨‹
```
å•æ¬¡æ‰§è¡Œï¼š
  è·å– 3 ä¸ª URL
  â†’ ç”Ÿæˆ Parser
  â†’ éªŒè¯
  å®Œæˆ
```

### æ–°æµç¨‹
```
è½®æ¬¡ 1ï¼šè·å– 3 ä¸ª URL â†’ ç”Ÿæˆ Schema v1 â†’ ç”Ÿæˆ Parser v1 â†’ éªŒè¯æ‰€æœ‰ URL
è½®æ¬¡ 2ï¼šè·å– 1 ä¸ªæ–° URL â†’ åˆå¹¶ Schema v2 â†’ ä¼˜åŒ– Parser v2 â†’ éªŒè¯æ‰€æœ‰ URL
è½®æ¬¡ 3ï¼šè·å– 1 ä¸ªæ–° URL â†’ åˆå¹¶ Schema v3 â†’ ä¼˜åŒ– Parser v3 â†’ éªŒè¯æ‰€æœ‰ URL
...
ç›´åˆ°å‡†ç¡®ç‡è¾¾åˆ°é˜ˆå€¼æˆ–è¿­ä»£æ¬¡æ•°ä¸Šé™
```

---

## ğŸ”„ å…³é”®æµç¨‹ç»†èŠ‚

### ç¬¬ä¸€è½®æµç¨‹

```
è¾“å…¥: URL [url1, url2, url3]

execute_single_round(1, [url1, url2, url3]):
  â”œâ”€ url1: HTML â†’ Screenshot â†’ JSON â†’ groundtruth_1.json
  â”œâ”€ url2: HTML â†’ Screenshot â†’ JSON â†’ groundtruth_2.json
  â””â”€ url3: HTML â†’ Screenshot â†’ JSON â†’ groundtruth_3.json
  â””â”€ return: urls_data = {url1: {...}, url2: {...}, url3: {...}}

_process_schema(1, urls_data):
  â”œâ”€ åˆå¹¶3ä¸ªJSON
  â”œâ”€ æå–Schema
  â””â”€ return: schema_v1.json

generate_or_update_parser(1, urls_data, None, None):
  â”œâ”€ é€‰æ‹©reference_html (url1çš„HTML)
  â”œâ”€ ä½¿ç”¨generate_parser_codeç”Ÿæˆ
  â””â”€ return: generated_parser_v1.py

validate_parser_on_all_urls("generated_parser_v1.py", all_urls):
  â”œâ”€ For each url in all_urls:
  â”‚   â”œâ”€ HTML â†’ Parser â†’ predicted_json
  â”‚   â”œâ”€ Load groundtruth_json
  â”‚   â”œâ”€ Calculate accuracy
  â”‚   â””â”€ Record
  â””â”€ return: overall_accuracy = 0.72
```

### ç¬¬äºŒè½®æµç¨‹

```
è¾“å…¥: URL [url4]

execute_single_round(2, [url4]):
  â”œâ”€ url4: HTML â†’ Screenshot â†’ JSON â†’ groundtruth_4.json
  â””â”€ return: urls_data = {url4: {...}}

_process_schema(2, urls_data, schema_v1):
  â”œâ”€ æ–°JSON (from url4)
  â”œâ”€ ä¸schema_v1åˆå¹¶
  â””â”€ return: schema_v2.json

generate_or_update_parser(2, urls_data, schema_v1, "generated_parser_v1.py"):
  â”œâ”€ é€‰æ‹©reference_html (url4çš„HTML)
  â”œâ”€ è¯»å–å‰ä¸€è½®ä»£ç 
  â”œâ”€ ä½¿ç”¨fix_parser_codeä¼˜åŒ–
  â”‚   â”œâ”€ è¾“å…¥ï¼šprevious_code + new_html + merged_schema
  â”‚   â”œâ”€ LLMæ“ä½œï¼šä¿ç•™å·²æœ‰é€»è¾‘ï¼Œæ·»åŠ æ–°å­—æ®µ
  â”‚   â””â”€ è¾“å‡ºï¼šoptimized_code
  â””â”€ return: generated_parser_v2.py

validate_parser_on_all_urls("generated_parser_v2.py", all_urls):
  â”œâ”€ For each url in all_urls:
  â”‚   â”œâ”€ HTML â†’ Parser â†’ predicted_json
  â”‚   â”œâ”€ Load groundtruth_json
  â”‚   â”œâ”€ Calculate accuracy
  â”‚   â””â”€ Record
  â””â”€ return: overall_accuracy = 0.81
```

---

## ğŸ“ˆ å‡†ç¡®ç‡è®¡ç®—æ–¹å¼

### å…¬å¼

```python
accuracy = 0.7 Ã— completeness + 0.3 Ã— similarity

completeness = |predicted_keys âˆ© groundtruth_keys| / |groundtruth_keys|
similarity = (type_matched_count) / |groundtruth_keys|
```

### ç¤ºä¾‹

```
Groundtruth JSON:
{
  "title": "Article",        # string
  "date": "2024-01-01",      # string
  "views": 100               # integer
}

Predicted JSON:
{
  "title": "Article",        # string âœ“
  "date": "2024-01-01",      # string âœ“
  "views": "100"             # string âœ— (type mismatch)
}

completeness = 3/3 = 1.0
similarity = 2/3 = 0.667
accuracy = 0.7 Ã— 1.0 + 0.3 Ã— 0.667 = 0.9
```

---

## ğŸ¯ éªŒè¯é€»è¾‘

### Groundtruthï¼ˆçœŸå€¼æ ‡ç­¾ï¼‰

- **æ¥æº**ï¼švLLM/å›¾ç‰‡è¯†åˆ«æå–çš„JSON
- **ä¿å­˜æ—¶æœº**ï¼šæ¯ä¸ªURLå¤„ç†åç«‹å³ä¿å­˜
- **ä¿å­˜ä½ç½®**ï¼š`output/groundtruth/{url_hash}.json`
- **æ ¼å¼**ï¼šä¸æå–JSONç›¸åŒ

### é¢„æµ‹å€¼

- **æ¥æº**ï¼šæœ€æ–°ç”Ÿæˆçš„Parseråœ¨ç›¸åŒURLä¸Šçš„è§£æç»“æœ
- **è®¡ç®—æ—¶æœº**ï¼šéªŒè¯é˜¶æ®µ
- **å¯¹æ¯”æ–¹å¼**ï¼šä¸groundtruthé€å­—æ®µå¯¹æ¯”

### å‡†ç¡®ç‡

- **è®¡ç®—æ—¶æœº**ï¼šæ¯è½®è¿­ä»£å
- **è®¡ç®—èŒƒå›´**ï¼šæ‰€æœ‰æä¾›çš„URLï¼ˆä¸ä»…ä»…æ˜¯æœ¬è½®å¤„ç†çš„ï¼‰
- **åˆ¤æ–­æ ‡å‡†**ï¼š
  - å­—æ®µå®Œæ•´æ€§ï¼šé¢„æµ‹JSONæ˜¯å¦åŒ…å«æ‰€æœ‰groundtruthå­—æ®µ
  - å€¼ç›¸ä¼¼åº¦ï¼šç›¸åŒå­—æ®µçš„ç±»å‹æ˜¯å¦åŒ¹é…
  - ç»¼åˆå¾—åˆ†ï¼š70%æƒé‡å®Œæ•´æ€§ï¼Œ30%æƒé‡ç›¸ä¼¼åº¦

### å¾ªç¯ç»ˆæ­¢æ¡ä»¶

1. `overall_accuracy â‰¥ accuracy_threshold` â†’ æˆåŠŸç»ˆæ­¢ âœ“
2. `round_num â‰¥ max_iterations` â†’ è¾¾åˆ°ä¸Šé™ â±
3. æ‰€æœ‰URLå·²å¤„ç†ä¸”æ— æ–°URL â†’ å®Œæˆ âœ“
4. ä»»ä½•æ­¥éª¤å¼‚å¸¸ â†’ å¤±è´¥ç»ˆæ­¢ âœ—

---

## ğŸ”§ é…ç½®å‚æ•°

### æ–°å¢é…ç½®

`config/settings.py` ä¸­å·²æ”¯æŒï¼š

```python
# è¿­ä»£å‚æ•°
max_iterations = 5              # æœ€å¤§è½®æ¬¡
success_threshold = 0.8         # å‡†ç¡®ç‡é˜ˆå€¼

# ä»£ç ç”Ÿæˆå‚æ•°
code_gen_temperature = 0.3      # ç”Ÿæˆæ¸©åº¦ï¼ˆè¶Šä½è¶Šç¨³å®šï¼‰
code_gen_max_tokens = 4000      # æœ€å¤§tokens

# è§†è§‰è¯†åˆ«å‚æ•°
vision_temperature = 0.2        # è¯†åˆ«æ¸©åº¦ï¼ˆè¶Šä½è¶Šå‡†ç¡®ï¼‰
```

---

## ğŸ“š æ–°å¢æ–‡æ¡£

1. **NEW_FLOW_GUIDE.md** - è¯¦ç»†çš„æµç¨‹è¯´æ˜
2. **ITERATION_WORKFLOW.md** - å®Œæ•´çš„å·¥ä½œæµç¨‹å›¾ç¤º
3. **QUICK_START.md** - å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

---

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### å‘½ä»¤è¡Œ

```bash
python main.py -f urls.txt -o output/my_project -t article
```

### Pythonä»£ç 

```python
from agent import ParserAgent

agent = ParserAgent(output_dir="output")

result = agent.run_iterations(
    urls=["url1", "url2", "url3", "url4", "url5"],
    domain="example.com",
    layout_type="article",
    max_iterations=3,
    accuracy_threshold=0.85
)

print(f"âœ“ æ€»è½®æ¬¡: {result['total_rounds']}")
print(f"âœ“ æœ€ç»ˆå‡†ç¡®ç‡: {result['overall_accuracy']:.2%}")
print(f"âœ“ æœ€ç»ˆParser: {result['final_parser_path']}")
```

---

## âœ¨ ä¸»è¦æ”¹è¿›

| æ”¹è¿›é¡¹ | æ—§ç‰ˆæœ¬ | æ–°ç‰ˆæœ¬ |
|--------|--------|--------|
| è¿­ä»£æ–¹å¼ | å•æ¬¡æ‰§è¡Œ | å¤šè½®å¾ªç¯ |
| Schemaå¤„ç† | ç›´æ¥ä½¿ç”¨ | è‡ªåŠ¨åˆå¹¶ |
| Parserç”Ÿæˆ | ä»é›¶å¼€å§‹ | å¢é‡ä¼˜åŒ– |
| éªŒè¯èŒƒå›´ | ä»…æœ¬è½®URL | æ‰€æœ‰URL |
| å‡†ç¡®ç‡è¿½è¸ª | ä»…è®°å½• | åŠ¨æ€è®¡ç®—+è¿½è¸ª |
| å¾ªç¯æ§åˆ¶ | æ—  | æ”¯æŒå‡†ç¡®ç‡é˜ˆå€¼ |
| é”™è¯¯æ¢å¤ | å•ç‚¹å¤±è´¥ | æ”¯æŒresume |

---

## ğŸ” éªŒè¯ä¿®æ”¹

### æ£€æŸ¥point 1ï¼šå•è½®æ‰§è¡Œ

```python
# éªŒè¯execute_single_roundèƒ½æ­£å¸¸å·¥ä½œ
result = executor.execute_single_round(1, ["url1"], "example.com", "article")
assert result['success']
assert len(result['urls_data']) > 0
```

### æ£€æŸ¥point 2ï¼šSchemaåˆå¹¶

```python
# éªŒè¯schemaåˆå¹¶é€»è¾‘
schema1 = {"title": {...}, "date": {...}}
schema2 = schema1.copy()
schema2["author"] = {...}  # æ–°å¢å­—æ®µ
assert "title" in schema2
assert "author" in schema2
```

### æ£€æŸ¥point 3ï¼šParserä¼˜åŒ–

```python
# éªŒè¯parserä¼˜åŒ–é€»è¾‘
result = executor.generate_or_update_parser(
    round_num=2,
    urls_data={...},
    previous_schema=schema1,
    previous_parser_path="path_to_v1.py"
)
assert result['success']
assert result['parser_path'].endswith('v2.py')
```

### æ£€æŸ¥point 4ï¼šå‡†ç¡®ç‡è®¡ç®—

```python
# éªŒè¯å‡†ç¡®ç‡è®¡ç®—
groundtruth = {"title": "Test", "date": "2024-01"}
predicted = {"title": "Test", "date": "2024-01"}
accuracy = executor._calculate_json_accuracy(groundtruth, predicted)
assert accuracy == 1.0
```

---

## ğŸ“‹ æ£€æŸ¥æ¸…å•

- [x] executor.py å®Œå…¨é‡å†™
- [x] orchestrator.py å®Œå…¨é‡å†™
- [x] code_fixer.py å®Œå…¨é‡å†™ï¼Œæ”¯æŒå¢é‡ä¼˜åŒ–
- [x] main.py æ›´æ–°ä½¿ç”¨æ–°æ–¹æ³•
- [x] éªŒè¯é€»è¾‘ä¿®æ”¹ä¸ºgroundtruth+é¢„æµ‹å€¼å¯¹æ¯”
- [x] æ”¯æŒå¤šè½®è¿­ä»£å¾ªç¯
- [x] æ”¯æŒSchemaåˆå¹¶
- [x] æ”¯æŒParserä¼˜åŒ–ï¼ˆåŸºäºå‰ä¸€è½®ï¼‰
- [x] æ”¯æŒå‡†ç¡®ç‡é˜ˆå€¼æ§åˆ¶
- [x] æ”¯æŒæœ€å¤§è¿­ä»£æ¬¡æ•°é™åˆ¶
- [x] è¯¦ç»†æ–‡æ¡£ç¼–å†™

---

## ğŸ‰ å®Œæˆ

æ‰€æœ‰éœ€æ±‚å·²å®ç°ã€‚ç³»ç»Ÿç°åœ¨æ”¯æŒï¼š

1. âœ… è·å–HTMLæºç 
2. âœ… æˆªå›¾
3. âœ… æå–JSONï¼ˆç¬¬äºŒè½®åˆå¹¶ï¼‰
4. âœ… ç”Ÿæˆ/ä¼˜åŒ–è§£æä»£ç ï¼ˆç¬¬ä¸€è½®ä»é›¶ï¼Œåç»­ä¼˜åŒ–ï¼‰
5. âœ… éªŒè¯å‡†ç¡®ç‡ï¼ˆgroundtruth vs é¢„æµ‹å€¼ï¼‰
6. âœ… å¤šè½®è¿­ä»£ç›´åˆ°è¾¾åˆ°é˜ˆå€¼

**ä¸‹ä¸€æ­¥**ï¼šè¿è¡Œ `python main.py -f urls.txt` å¼€å§‹ä½¿ç”¨ï¼

